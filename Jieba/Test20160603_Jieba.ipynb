{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#encoding = utf-8\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本斷詞的用法：\n",
    "### 共3種，分別是精確模式、全模式、搜尋引擎模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\Big Data\\Python\\Workspace\\JiebaCut\\dictionary\\dict.txt.big.txt ...\n",
      "Loading model from cache c:\\users\\albert\\appdata\\local\\temp\\jieba.ud2b327aa99bbd230f111a204905f4a87.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 精確模式:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.799 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我/ 來到/ 一個/ 島它/ 叫/ 卡/ 加布/ 列島/ 有/ 隻身/ 穿/ 七彩/ 衣/ 的/ 鳥/ 對/ 著/ 我/ 微笑/\n"
     ]
    }
   ],
   "source": [
    "jieba.set_dictionary('D:\\\\Big Data\\\\Python\\\\Workspace\\\\JiebaCut\\\\dictionary\\\\dict.txt.big.txt') #載入繁體詞典\n",
    "setence = jieba.cut('我來到一個島它叫卡加布列島有隻身穿七彩衣的鳥對著我微笑') #cut_all這個參數是預設false，也就是預設為精確模式\n",
    "print 'Output 精確模式:' #精確模式，試圖將句子最精確地切開，適合文本分析；\n",
    "for word in setence:\n",
    "    print word + '/',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\Big Data\\Python\\Workspace\\JiebaCut\\dictionary\\dict.txt.big.txt ...\n",
      "Loading model from cache c:\\users\\albert\\appdata\\local\\temp\\jieba.ud2b327aa99bbd230f111a204905f4a87.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 全模式: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.768 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我/ 來到/ 一個/ 島/ 它/ 叫/ 卡加/ 加布/ 布列/ 列島/ 有/ 隻身/ 身穿/ 七彩/ 彩衣/ 的/ 鳥/ 對/ 著/ 我/ 微笑/\n"
     ]
    }
   ],
   "source": [
    "jieba.set_dictionary('D:\\\\Big Data\\\\Python\\\\Workspace\\\\JiebaCut\\\\dictionary\\\\dict.txt.big.txt')\n",
    "setence = jieba.cut('我來到一個島它叫卡加布列島有隻身穿七彩衣的鳥對著我微笑', cut_all = True)\n",
    "print 'Output 全模式: ' #全模式，把句子中所有的可以成詞的詞語都掃描出來, 速度非常快，但是不能解決歧義；\n",
    "for word in setence:\n",
    "    print word + '/',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\Big Data\\Python\\Workspace\\JiebaCut\\dictionary\\dict.txt.big.txt ...\n",
      "Loading model from cache c:\\users\\albert\\appdata\\local\\temp\\jieba.ud2b327aa99bbd230f111a204905f4a87.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 搜尋引擎模式: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.808 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我/ 來到/ 一個/ 島它/ 叫/ 卡/ 加布/ 列島/ 有/ 隻身/ 穿/ 七彩/ 衣/ 的/ 鳥/ 對/ 著/ 我/ 微笑/\n"
     ]
    }
   ],
   "source": [
    "jieba.set_dictionary('D:\\\\Big Data\\\\Python\\\\Workspace\\\\JiebaCut\\\\dictionary\\\\dict.txt.big.txt')\n",
    "setence = jieba.cut_for_search('我來到一個島它叫卡加布列島有隻身穿七彩衣的鳥對著我微笑')\n",
    "print 'Output 搜尋引擎模式: ' #搜尋引擎模式，在精確模式的基礎上，對長詞再次切分，提高召回率，適合用於搜尋引擎分詞。\n",
    "for word in setence:\n",
    "    print word + '/',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入辭典、自行定義詞典\n",
    "### 第一個是未載入自行定義詞典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\Big Data\\Python\\Workspace\\JiebaCut\\dictionary\\dict.txt.big.txt ...\n",
      "Loading model from cache c:\\users\\albert\\appdata\\local\\temp\\jieba.ud2b327aa99bbd230f111a204905f4a87.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 精確模式:\n",
      "﻿"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.797 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 和 朋友 一如 往常 唱唱 K 歌 \n",
      "下 一攤 宵夜 火鍋 吃吃喝喝 \n",
      "那 狂歡 一成不變 一樣 快快樂樂 \n",
      "一樣 失 真的 夜晚 和 清晨 \n",
      "\n",
      "那 生活 勉強 還能 自得其樂 \n",
      "而 關上燈 獨自一人 \n",
      "嘴角 笑 著 眼眶 為何 濕 了 \n",
      "\n",
      "我 怎麼 哭 了 \n",
      "當我 偶然 想起 了 \n",
      "想起 有 你 的 時刻 \n",
      "哼起 你 最愛 的 歌 \n",
      "點了 你 愛的 菜色 \n",
      "為 什麼 哭 呢 \n",
      "明明 撫平 了 傷痕 \n",
      "好好 過我 的 人生 \n",
      "絕不 是 因為 你 那 無心 一句 \n",
      "最近 如何 \n",
      "\n",
      "那 孤單 其實 沒有 想像 殘忍 \n",
      "找 個人 逛街 玩樂 都 是 選擇 \n",
      "但 睡 前 那句 晚安 我 該 對 誰 說 呢 \n",
      "一 想到 這心 就 不堪 負荷 \n",
      "\n",
      "那 生活 勉強 還能 自得其樂 \n",
      "而 關上燈 獨自一人 \n",
      "誰 會 在乎 我 的 喜怒哀樂 \n",
      "\n",
      "我 怎麼 哭 了 \n",
      "當我 偶然 想起 了 \n",
      "想起 有 你 的 時刻 \n",
      "一起 看過 的 景色 \n",
      "還沒 實現 的 旅程 \n",
      "為 什麼 哭 呢 \n",
      "明明 撫平 了 傷痕 \n",
      "好好 過我 的 人生 \n",
      "絕不 是 又 想起 了 \n",
      "我們 曾 相許 的 永恆 \n",
      "\n",
      "我 不再 哭 了 \n",
      "當我 漸漸 習慣 了 \n",
      "習慣 偽裝著 快樂 \n",
      "習慣 再 愛 一個 人 \n",
      "就算 不 那麼 狂熱 \n",
      "你 愛著 誰 呢 \n",
      "要 比 我們 更 深刻 \n",
      "完成 我們 未 完成 \n",
      "為 你 的 幸福 犧牲 \n",
      "也 算愛的 一種 美德 \n",
      "\n",
      "我 衷心祝福 你 的 \n",
      "可是 我 卻 怎麼 哭 了\n"
     ]
    }
   ],
   "source": [
    "#encoding = utf-8\n",
    "jieba.set_dictionary('D:\\\\Big Data\\\\Python\\\\Workspace\\\\JiebaCut\\\\dictionary\\\\dict.txt.big.txt')\n",
    "#若是用繁體字，則是用繁體詞典(官方提供)，會較原本預設簡體較準確\n",
    "#上面這個是萌典的詞典，可是不知道為何無法直接用set_dict的方式載入，再研究\n",
    "content = open('D:\\\\Big Data\\\\Python\\\\Workspace\\\\JiebaCut\\\\txtFiles\\\\testLyrics_fixed.txt', 'r').read()\n",
    "print '精確模式:'\n",
    "words = jieba.cut(content, cut_all = False)\n",
    "for word in words:\n",
    "    print word,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二個是已載入自行定義詞典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\Big Data\\Python\\Workspace\\JiebaCut\\dictionary\\dict.txt.big.txt ...\n",
      "Loading model from cache c:\\users\\albert\\appdata\\local\\temp\\jieba.ud2b327aa99bbd230f111a204905f4a87.cache\n",
      "Loading model cost 0.797 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精確模式:\n",
      "﻿ 和 朋友 一如往常 唱唱 K歌 \n",
      "下一攤 宵夜 火鍋 吃吃喝喝 \n",
      "那 狂歡 一成不變 一樣 快快樂樂 \n",
      "一樣 失 真的 夜晚 和 清晨 \n",
      "\n",
      "那 生活 勉強 還能 自得其樂 \n",
      "而 關上燈 獨自一人 \n",
      "嘴角 笑 著 眼眶 為何 濕 了 \n",
      "\n",
      "我 怎麼 哭了 \n",
      "當我 偶然 想起 了 \n",
      "想起 有 你的 時刻 \n",
      "哼起 你 最愛 的 歌 \n",
      "點了 你 愛的 菜色 \n",
      "為什麼 哭 呢 \n",
      "明明 撫平 了 傷痕 \n",
      "好好 過 我的 人生 \n",
      "絕不 是 因為 你 那 無心 一句 \n",
      "最近 如何 \n",
      "\n",
      "那 孤單 其實 沒有 想像 殘忍 \n",
      "找 個人 逛街 玩樂 都 是 選擇 \n",
      "但 睡前 那句 晚安 我 該 對 誰 說 呢 \n",
      "一 想到 這心 就 不堪 負荷 \n",
      "\n",
      "那 生活 勉強 還能 自得其樂 \n",
      "而 關上燈 獨自一人 \n",
      "誰 會 在乎 我的 喜怒哀樂 \n",
      "\n",
      "我 怎麼 哭了 \n",
      "當我 偶然 想起 了 \n",
      "想起 有 你的 時刻 \n",
      "一起 看過 的 景色 \n",
      "還沒 實現 的 旅程 \n",
      "為什麼 哭 呢 \n",
      "明明 撫平 了 傷痕 \n",
      "好好 過 我的 人生 \n",
      "絕不 是 又 想起 了 \n",
      "我們 曾 相許 的 永恆 \n",
      "\n",
      "我 不再 哭了 \n",
      "當我 漸漸 習慣 了 \n",
      "習慣 偽裝 著 快樂 \n",
      "習慣 再 愛 一個 人 \n",
      "就算 不 那麼 狂熱 \n",
      "你 愛著 誰 呢 \n",
      "要 比 我們 更 深刻 \n",
      "完成 我們 未 完成 \n",
      "為 你的 幸福 犧牲 \n",
      "也 算愛的 一種 美德 \n",
      "\n",
      "我 衷心祝福 你的 \n",
      "可是 我 卻 怎麼 哭了\n"
     ]
    }
   ],
   "source": [
    "#encoding = utf-8\n",
    "jieba.set_dictionary('D:\\\\Big Data\\\\Python\\\\Workspace\\\\JiebaCut\\\\dictionary\\\\dict.txt.big.txt')\n",
    "jieba.load_userdict('D:\\\\Big Data\\\\Python\\\\Workspace\\\\JiebaCut\\\\dictionary\\\\lyricsDict.txt') #載入自行定義的詞典\n",
    "content = open('D:\\\\Big Data\\\\Python\\\\Workspace\\\\JiebaCut\\\\txtFiles\\\\testLyrics_fixed.txt', 'r').read()\n",
    "print '精確模式:'\n",
    "words = jieba.cut(content, cut_all = False)\n",
    "for word in words:\n",
    "    print word,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Link:http://blog.fukuball.com/ru-he-shi-yong-jieba-jie-ba-zhong-wen-fen-ci-cheng-shi/\n",
    "## Link:https://github.com/pig7788/jieba\n",
    "## Link:http://www.cc.ntu.edu.tw/chinese/epaper/0031/20141220_3103.html\n",
    "## Link:https://github.com/YuHsuanLin/ETL/tree/master/jieba__dictionary\n",
    "## Link:https://blog.longwin.com.tw/2014/09/python-list-print-chinese-2014/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jieba的TF-IDF萃取功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache c:\\users\\albert\\appdata\\local\\temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字詞 \t詞頻\n",
      "============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.432 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "想起 \t0.463363081508\n",
      "怎麼 \t0.278017848905\n",
      "我們 \t0.278017848905\n",
      "一樣 \t0.185345232603\n",
      "上燈 \t0.185345232603\n",
      "自得 \t0.185345232603\n",
      "人生 \t0.185345232603\n",
      "一人 \t0.185345232603\n",
      "其樂 \t0.185345232603\n",
      "當我 \t0.185345232603\n",
      "而關 \t0.185345232603\n",
      "什麼 \t0.185345232603\n",
      "撫平 \t0.185345232603\n",
      "好好 \t0.185345232603\n",
      "過我 \t0.185345232603\n",
      "生活 \t0.185345232603\n",
      "傷痕 \t0.185345232603\n",
      "不是 \t0.185345232603\n",
      "獨自 \t0.185345232603\n",
      "明明 \t0.120024531217\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "import uniout\n",
    "content = open('D:\\\\BigData\\\\Python\\\\Workspace\\\\TextMining\\\\JiebaCut\\\\txtFiles\\\\testLyrics_fixed.txt', 'r').read()\n",
    "jieba.analyse.set_idf_path('D:\\\\BigData\\\\Python\\\\Workspace\\\\TextMining\\\\JiebaCut\\\\\\\\dictionary\\\\idf.txt.big')\n",
    "#這個是自行將idf頻率檔，設置的方法\n",
    "print '字詞', '\\t詞頻'\n",
    "print ('=' * 12)\n",
    "for ele, weight in jieba.analyse.extract_tags(content, topK = 20, withFlag = False, allowPOS = (), withWeight = True):\n",
    "    print ele, '\\t' + str(weight)\n",
    "#topK 為返回幾個 TF/IDF 權重最大的關鍵字，預設值為 20\n",
    "# withWeight 為是否一併返回關鍵字權重值，預設值為 False\n",
    "# allowPOS 僅包括指定詞性的詞，預設值為空，即不篩選\n",
    "# jieba.analyse.TFIDF(idf_path=None) 新建 TFIDF 實例，idf_path 為 IDF 頻率檔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jieba的TextRank萃取功能\n",
    "## Link:https://wefollownews.appspot.com/cittopnews201408_2/9302.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "想起 1.0\n",
      "生活 0.987090389314\n",
      "選擇 0.986404254311\n",
      "美德 0.898625154392\n",
      "算愛 0.89185587211\n",
      "自得 0.75642210737\n",
      "勉強 0.747076248984\n",
      "實現 0.731913023148\n",
      "睡前 0.728341094754\n",
      "笑著 0.683974958555\n",
      "裝著 0.683778121823\n",
      "朋友 0.683778121823\n",
      "撫平 0.683778121823\n",
      "在乎 0.683778121823\n",
      "沒有 0.683778121823\n",
      "火鍋 0.683778121823\n",
      "眼眶 0.680775149548\n",
      "習慣 0.678762301922\n",
      "喜怒 0.678762301922\n",
      "傷痕 0.678762301922\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "import uniout\n",
    "content = open('D:\\\\BigData\\\\Python\\\\Workspace\\\\TextMining\\\\JiebaCut\\\\txtFiles\\\\testLyrics_fixed.txt', 'r').read()\n",
    "for ele, weight in jieba.analyse.textrank(content, topK = 20, withWeight = True):\n",
    "    print ele, weight\n",
    "#將待抽取關鍵字的文本進行分詞\n",
    "#以固定視窗大小(預設為5，通過span屬性調整)，詞之間的共現關係，構建圖\n",
    "#計算圖中節點的PageRank，注意是無向帶權圖\n",
    "#若要使用詞性過濾，範例參數：allowPOS=('ns', 'n', 'vn', 'v')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
