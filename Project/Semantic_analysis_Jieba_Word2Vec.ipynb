{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec訓練過程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jieba, codecs, word2vec, gensim, logging, scipy\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "將Ptt與Backpackers的文章做合併。\n",
    "'''\n",
    "with open(r'D:\\BigData\\Python\\Workspace\\TextMining\\JiebaCut\\txtFiles\\word2Vec_Material.txt', 'a') as dataWrite:\n",
    "    for context in codecs.open(r'D:\\BigData\\Project\\Travel\\ptt_TourAgency_evaluation\\Japan\\Data\\TourAgency\\CleanedData\\Word2Vec\\word2Vec_article(Ptt).txt', 'r', 'utf-8'):\n",
    "        dataWrite.write(context.encode('utf-8'))\n",
    "    for context in codecs.open(r'D:\\BigData\\Project\\Travel\\Backpackers\\Japan\\Data\\TourAgency\\CleanedData\\Word2Vec\\word2Vec_article(Backpackers).txt', 'r', 'utf-8'):\n",
    "        dataWrite.write(context.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\BigData\\Python\\Workspace\\TextMining\\Project\\dictionary_for_semantic_analysis\\wordDict\\dict.txt.big.txt ...\n",
      "Loading model from cache c:\\users\\albert\\appdata\\local\\temp\\jieba.u644c1e3a7131d16659188b660829ecb9.cache\n",
      "Loading model cost 0.724 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "jieba.set_dictionary(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\dictionary_for_semantic_analysis\\wordDict\\dict.txt.big.txt')\n",
    "jieba.load_userdict(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\dictionary_for_semantic_analysis\\wordDict\\dict_revised_total_cleared(UTF-8).txt.big.txt')\n",
    "jieba.load_userdict(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\dictionary_for_semantic_analysis\\wordDict\\combinedDict.txt')\n",
    "jieba.load_userdict(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\dictionary_for_semantic_analysis\\wordDict\\Adj_Cleared_by_Albert.txt')\n",
    "'''\n",
    "載入情緒用語的相關詞彙，並且逐行讀取時，就做一次分詞。\n",
    "最後加入到，word2VecList內作為Word2Vec的訓練詞料。\n",
    "'''\n",
    "word2VecList = list()\n",
    "with open(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\txtFiles\\word2Vec_Material.txt', 'r') as dataRead:\n",
    "        for lines in dataRead.readlines():\n",
    "            stopWords = list(jieba.cut(lines))\n",
    "            word2VecList.append(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(word2VecList, window = 5, min_count = 1, size = 200, workers = 8, sg=1)\n",
    "#開始訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\trainConquency\\word2Vec_test3.txt')\n",
    "#將訓練結果存檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "違法 \t0.849712908268\n",
      "說謊 \t0.84786272049\n",
      "詐欺 \t0.841739058495\n",
      "case \t0.833042681217\n",
      "解讀 \t0.83282148838\n",
      "誤解 \t0.828310132027\n",
      "被動 \t0.828264832497\n",
      "傲慢 \t0.828174114227\n",
      "做人 \t0.82512229681\n",
      "逃避 \t0.824803352356\n",
      "奧客 \t0.824630856514\n",
      "好怕 \t0.824303388596\n",
      "好不 \t0.82332777977\n",
      "跑路 \t0.822301089764\n",
      "發錯 \t0.821645617485\n",
      "出包 \t0.819756507874\n",
      "出錯 \t0.819512069225\n",
      "誤會 \t0.817753911018\n",
      "做生意 \t0.817503452301\n",
      "個案 \t0.815926551819\n"
     ]
    }
   ],
   "source": [
    "for name, weight in model.most_similar(u'詐騙', topn = 20):\n",
    "    print name, '\\t', weight\n",
    "#將訓練結果印出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好累 0.869031429291\n",
      "似的 0.856338500977\n",
      "又貴 0.85406935215\n",
      "很不爽 0.852548599243\n",
      "FU 0.850278973579\n",
      "餓 0.846414387226\n",
      "............. 0.846063911915\n",
      "尷尬 0.845596671104\n",
      "詭異 0.845062792301\n",
      "傻 0.843250215054\n",
      "阿彌陀佛 0.843212127686\n",
      "痛 0.843107104301\n",
      "也不少 0.842430233955\n",
      "不好了 0.841335117817\n",
      "要死 0.841297268867\n",
      "很慘 0.840388536453\n",
      "睡著 0.840152144432\n",
      "很煩 0.839766919613\n",
      "好笑 0.837970972061\n",
      "不在意 0.83763474226\n",
      "很累 0.83725965023\n",
      "也不見得 0.83708435297\n",
      "難吃 0.836709618568\n",
      "不值 0.836354970932\n",
      "不能不 0.836342096329\n",
      "買得 0.83615732193\n",
      "會累 0.833863735199\n",
      "大不了 0.833631277084\n",
      "未免 0.832597374916\n",
      "很不高興 0.83243227005\n",
      "發呆 0.832369208336\n",
      "超趕 0.832190096378\n",
      "很怪 0.83142220974\n",
      "無所謂 0.830769062042\n",
      "回不來 0.830478072166\n",
      "更慘 0.829511404037\n",
      "幹嗎 0.829481720924\n",
      "蠻好 0.828764975071\n",
      "很熱 0.827906727791\n",
      "難堪 0.827882289886\n",
      "耗 0.827749490738\n",
      "很恐怖 0.827337622643\n",
      "好差 0.827238202095\n",
      "很沒禮貌 0.82714176178\n",
      "一推 0.826416909695\n",
      "訂廉航 0.826294541359\n",
      "對號入座 0.825987815857\n",
      "腦袋 0.825469732285\n",
      "全退 0.824924170971\n",
      "XDD 0.824847340584\n",
      "術 0.824205994606\n",
      "餓肚子 0.824026525021\n",
      "很不方便 0.823790431023\n",
      "措手不及 0.823397755623\n",
      "很無言 0.823312699795\n",
      "又便宜 0.822997391224\n",
      "很會 0.822881698608\n",
      "花錢買 0.822797894478\n",
      "也不會強迫 0.822709619999\n",
      "衰 0.822520971298\n",
      "只怕 0.822498977184\n",
      "地步 0.822430312634\n",
      "難聽 0.822186112404\n",
      "扯 0.821966767311\n",
      "默默 0.821714282036\n",
      "很久以前 0.821244716644\n",
      "換我 0.821012973785\n",
      "爽 0.820870280266\n",
      "XDXD 0.820513129234\n",
      "有點誇張 0.820348322392\n",
      "很糟 0.820305168629\n",
      "吃虧 0.81992816925\n",
      "另當別論 0.819825053215\n",
      "回頭路 0.81956744194\n",
      "說不過去 0.81914639473\n",
      "這麼貴 0.818863511086\n",
      "怪怪的 0.818743824959\n",
      "活該 0.818733930588\n",
      "在乎 0.818722724915\n",
      "碰 0.818514108658\n",
      "好賺 0.818224787712\n",
      "一眼 0.8180590868\n",
      "有點傻眼 0.817716062069\n",
      "很不滿意 0.817522525787\n",
      "很難過 0.817451000214\n",
      "早起 0.817263424397\n",
      "砸 0.816992282867\n",
      "多心 0.816991090775\n",
      "睡得 0.816892385483\n",
      "莫名其妙 0.81676530838\n",
      "被關 0.81670331955\n",
      "天價 0.816646337509\n",
      "唬爛 0.816372275352\n",
      "很鳥 0.816298723221\n",
      "天真 0.81626278162\n",
      "很衰 0.816089630127\n",
      "就夠 0.815650820732\n",
      "透 0.815525531769\n",
      "出狀況 0.814591467381\n",
      "放寬心 0.814543366432\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "這邊是讀取訓練結果，可以不用再重新訓練。\n",
    "使用most_similar這個方法做字詞的查詢，並且顯示前N個相似字詞。\n",
    "'''\n",
    "load_model = Word2Vec.load(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\trainConquency\\word2Vec_test2.txt')\n",
    "for name, weight in load_model.most_similar(u'累', topn = 100):\n",
    "    print name, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10091001,  0.20380558, -0.14135464,  0.20689818,  0.08065707,\n",
       "       -0.14033918,  0.09613333, -0.01830177, -0.00331105,  0.03971123,\n",
       "        0.21693541,  0.02845153, -0.30570483,  0.10994349,  0.12161885,\n",
       "        0.13875365, -0.10543536,  0.1133725 , -0.04878392,  0.02331437,\n",
       "       -0.1019199 ,  0.27709708,  0.06472345,  0.01585715,  0.12199115,\n",
       "       -0.04790941,  0.11972708,  0.02711636, -0.0875293 ,  0.09650326,\n",
       "        0.19493997, -0.02745498,  0.00250377,  0.07074796,  0.11411554,\n",
       "        0.19009888, -0.07684618,  0.08687522,  0.01784826, -0.11686379,\n",
       "        0.13255355, -0.06983697, -0.07092857, -0.06289294, -0.03779208,\n",
       "       -0.00807454, -0.08978826,  0.10044585,  0.05361647, -0.07717983,\n",
       "       -0.07854116, -0.03607492,  0.08362368,  0.12428655,  0.09205086,\n",
       "       -0.06187516,  0.23629829, -0.04901069,  0.05036921,  0.1876305 ,\n",
       "        0.1477668 , -0.099998  , -0.16505939,  0.03440215, -0.02177471,\n",
       "        0.14223373, -0.05831927,  0.09625965,  0.06793021,  0.09265986,\n",
       "       -0.00259128, -0.01015103,  0.09163   , -0.06636903, -0.1122276 ,\n",
       "       -0.00874658,  0.0084533 ,  0.05468522,  0.11282286,  0.21089439,\n",
       "       -0.04754286, -0.14960536,  0.1299063 ,  0.25629777,  0.06042645,\n",
       "       -0.04991091,  0.31058282, -0.10603262,  0.03222882,  0.11525383,\n",
       "        0.11214577,  0.1430212 , -0.11533346, -0.06045258,  0.10679992,\n",
       "        0.29308617, -0.21296319, -0.11155503, -0.09902865,  0.09256038,\n",
       "       -0.05532592, -0.2484073 , -0.07749059, -0.04624774,  0.09025349,\n",
       "       -0.0107998 , -0.0994845 ,  0.03770782, -0.095424  ,  0.15444277,\n",
       "        0.17897786, -0.07392191,  0.23015314, -0.12985477, -0.18336004,\n",
       "       -0.11278943, -0.07762662,  0.04168941,  0.24057631,  0.04324254,\n",
       "        0.24385788,  0.02901646, -0.01480209,  0.23947832,  0.09877372,\n",
       "       -0.07287943,  0.0299808 , -0.00321367, -0.09811126,  0.12788171,\n",
       "       -0.12348733, -0.11208726,  0.06959263, -0.08463363,  0.04852872,\n",
       "        0.09566014, -0.24370775, -0.08395067, -0.06975017, -0.20984131,\n",
       "        0.10656552, -0.15482204,  0.03055314,  0.07711248,  0.22494818,\n",
       "       -0.03620499,  0.02109094, -0.04506844,  0.09299686,  0.03315258,\n",
       "       -0.03903901, -0.11495807,  0.30616981, -0.15104091, -0.05468432,\n",
       "       -0.07708869,  0.01963159,  0.12526207,  0.47837621, -0.09724386,\n",
       "        0.08781943, -0.0777515 ,  0.28546038, -0.27956307, -0.0890204 ,\n",
       "        0.09127615, -0.18049273, -0.12777737, -0.05164996, -0.02692593,\n",
       "        0.00370617, -0.1412314 , -0.16756913, -0.14260875,  0.0883661 ,\n",
       "        0.31519216, -0.12521002,  0.13288458, -0.25221744,  0.21247528,\n",
       "       -0.00604237, -0.1073035 , -0.13426255,  0.03112797, -0.14077806,\n",
       "        0.03619255, -0.03758753,  0.13467592,  0.05120847, -0.04468783,\n",
       "       -0.01955738,  0.00368612, -0.12210057, -0.04360028,  0.24367468,\n",
       "       -0.1918464 , -0.02458055,  0.22725508, -0.01994203, -0.00201876], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[u'實惠']\n",
    "#做單詞查詢，可以看到這個詞與其他字詞的餘弦相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link:https://blog.liang2.tw/2015Talk-Chinese-Search/#tf-idf-in-action\n",
    "# Link:http://city.shaform.com/blog/2014/11/04/word2vec.html\n",
    "# Link:http://blog.csdn.net/heyongluoyao8/article/details/43488765\n",
    "# Link:http://ju.outofmemory.cn/entry/80023\n",
    "# Link:https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words\n",
    "# Link:https://read01.com/J8oGa.html\n",
    "# Link:https://ingramchen.io/blog/2014/06/elasticsearch.html\n",
    "# Link:https://radimrehurek.com/gensim/models/word2vec.html\n",
    "# Link:http://city.shaform.com/blog/2015/08/30/spark-for-word2vec.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
