{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec訓練過程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jieba, codecs, word2vec, gensim, logging, scipy\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "將Ptt與Backpackers的文章做合併。\n",
    "'''\n",
    "with open(r'D:\\BigData\\Python\\Workspace\\TextMining\\JiebaCut\\txtFiles\\word2Vec_Material.txt', 'a') as dataWrite:\n",
    "    for context in codecs.open(r'D:\\BigData\\Project\\Travel\\ptt_TourAgency_evaluation\\Japan\\Data\\TourAgency\\CleanedData\\Word2Vec\\word2Vec_article(Ptt).txt', 'r', 'utf-8'):\n",
    "        dataWrite.write(context.encode('utf-8'))\n",
    "    for context in codecs.open(r'D:\\BigData\\Project\\Travel\\Backpackers\\Japan\\Data\\TourAgency\\CleanedData\\Word2Vec\\word2Vec_article(Backpackers).txt', 'r', 'utf-8'):\n",
    "        dataWrite.write(context.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from D:\\BigData\\Python\\Workspace\\TextMining\\Project\\dictionary_for_semantic_analysis\\wordDict\\dict.txt.big.txt ...\n",
      "Loading model from cache c:\\users\\albert\\appdata\\local\\temp\\jieba.u644c1e3a7131d16659188b660829ecb9.cache\n",
      "Loading model cost 0.724 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "jieba.set_dictionary(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\dictionary_for_semantic_analysis\\wordDict\\dict.txt.big.txt')\n",
    "jieba.load_userdict(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\dictionary_for_semantic_analysis\\wordDict\\dict_revised_total_cleared(UTF-8).txt.big.txt')\n",
    "jieba.load_userdict(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\dictionary_for_semantic_analysis\\wordDict\\combinedDict.txt')\n",
    "jieba.load_userdict(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\dictionary_for_semantic_analysis\\wordDict\\Adj_Cleared_by_Albert.txt')\n",
    "'''\n",
    "載入情緒用語的相關詞彙，並且逐行讀取時，就做一次分詞。\n",
    "最後加入到，word2VecList內作為Word2Vec的訓練詞料。\n",
    "'''\n",
    "word2VecList = list()\n",
    "with open(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\txtFiles\\word2Vec_Material.txt', 'r') as dataRead:\n",
    "        for lines in dataRead.readlines():\n",
    "            stopWords = list(jieba.cut(lines))\n",
    "            word2VecList.append(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(word2VecList, window = 5, min_count = 1, size = 200, workers = 8, sg=1)\n",
    "#開始訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\trainConquency\\word2Vec_test3.txt')\n",
    "#將訓練結果存檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "違法 \t0.849712908268\n",
      "說謊 \t0.84786272049\n",
      "詐欺 \t0.841739058495\n",
      "case \t0.833042681217\n",
      "解讀 \t0.83282148838\n",
      "誤解 \t0.828310132027\n",
      "被動 \t0.828264832497\n",
      "傲慢 \t0.828174114227\n",
      "做人 \t0.82512229681\n",
      "逃避 \t0.824803352356\n",
      "奧客 \t0.824630856514\n",
      "好怕 \t0.824303388596\n",
      "好不 \t0.82332777977\n",
      "跑路 \t0.822301089764\n",
      "發錯 \t0.821645617485\n",
      "出包 \t0.819756507874\n",
      "出錯 \t0.819512069225\n",
      "誤會 \t0.817753911018\n",
      "做生意 \t0.817503452301\n",
      "個案 \t0.815926551819\n"
     ]
    }
   ],
   "source": [
    "for name, weight in model.most_similar(u'詐騙', topn = 20):\n",
    "    print name, '\\t', weight\n",
    "#將訓練結果印出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不高興 0.823772668839\n",
      "貪小便宜 0.813368439674\n",
      "唬爛 0.808220982552\n",
      "不划算 0.806670665741\n",
      "被騙 0.805783569813\n",
      "活該 0.805532753468\n",
      "笨蛋 0.803521513939\n",
      "很慘 0.800624847412\n",
      "想想 0.800486445427\n",
      "得了 0.798668861389\n",
      "難看 0.796682596207\n",
      "會理 0.795646190643\n",
      "很不爽 0.795352935791\n",
      "難聽 0.795229554176\n",
      "奧客 0.794540762901\n",
      "對不起 0.793528318405\n",
      "腦袋 0.793328583241\n",
      "兇 0.793253540993\n",
      "很不高興 0.792618811131\n",
      "比較舒服 0.792508006096\n",
      "嫌 0.792476058006\n",
      "對號入座 0.792055010796\n",
      "態度不好 0.791698932648\n",
      "大不了 0.791332483292\n",
      "修養 0.790466189384\n",
      "不了了之 0.790376961231\n",
      "FU 0.790179252625\n",
      "貪便宜 0.789689302444\n",
      "認了 0.789271473885\n",
      "同情 0.788519144058\n",
      "沒什麼好 0.78787958622\n",
      "風涼話 0.787465214729\n",
      "做生意 0.785229146481\n",
      "總比 0.7848123312\n",
      "虧 0.784600198269\n",
      "好賺 0.784326672554\n",
      "很無言 0.784266591072\n",
      "不買 0.78381729126\n",
      "天價 0.783672332764\n",
      "有錢 0.783636212349\n",
      "窮 0.78338432312\n",
      "沒錢 0.783324122429\n",
      "老練 0.783312261105\n",
      "了事 0.78294801712\n",
      "無所謂 0.782743692398\n",
      "勇敢 0.782534122467\n",
      "理他 0.7819699049\n",
      "好抱怨 0.781215190887\n",
      "大爺 0.780019521713\n",
      "看運氣 0.77979528904\n",
      "傻 0.779740929604\n",
      "老實 0.779651403427\n",
      "過份 0.779427289963\n",
      "很不舒服 0.779126644135\n",
      "好幾千 0.778950572014\n",
      "給錢 0.778568744659\n",
      "動不動 0.778518438339\n",
      "好笑 0.778311908245\n",
      "硬要 0.778200924397\n",
      "想太多 0.777962565422\n",
      "多心 0.777763724327\n",
      "沒有好 0.777592658997\n",
      "老天 0.777010440826\n",
      "解讀 0.776713848114\n",
      "分手 0.776709079742\n",
      "很怪 0.776629924774\n",
      "不該 0.776288628578\n",
      "很不開心 0.776051640511\n",
      "砸 0.775848686695\n",
      "吃虧 0.775771737099\n",
      "上當 0.775233149529\n",
      "跳針 0.775194168091\n",
      "心甘情願 0.775134444237\n",
      "罵人 0.775040328503\n",
      "工讀生 0.77468764782\n",
      "還敢 0.774578809738\n",
      "一肚子火 0.774454474449\n",
      "看不懂 0.774392485619\n",
      "ㄠ 0.774278879166\n",
      "阻止 0.774142682552\n",
      "可惡 0.773902177811\n",
      "擺 0.773840129375\n",
      "囂張 0.773728966713\n",
      "變好 0.773594975471\n",
      "丟臉 0.773279190063\n",
      "會怕 0.773218154907\n",
      "回不來 0.772941231728\n",
      "受不了 0.772745490074\n",
      "那篇 0.77265226841\n",
      "那句話 0.772482037544\n",
      "受氣 0.772212922573\n",
      "激動 0.772181928158\n",
      "老話 0.771968960762\n",
      "委婉 0.771800398827\n",
      "爽 0.771524190903\n",
      "在乎 0.771396160126\n",
      "護航 0.771261096001\n",
      "就當 0.770978808403\n",
      "不能不 0.770918011665\n",
      "自認 0.770789563656\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "這邊是讀取訓練結果，可以不用再重新訓練。\n",
    "使用most_similar這個方法做字詞的查詢，並且顯示前N個相似字詞。\n",
    "'''\n",
    "load_model = Word2Vec.load(r'D:\\BigData\\Python\\Workspace\\TextMining\\Project\\trainConquency\\word2Vec_test2.txt')\n",
    "for name, weight in load_model.most_similar(u'不爽', topn = 100):\n",
    "    print name, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10091001,  0.20380558, -0.14135464,  0.20689818,  0.08065707,\n",
       "       -0.14033918,  0.09613333, -0.01830177, -0.00331105,  0.03971123,\n",
       "        0.21693541,  0.02845153, -0.30570483,  0.10994349,  0.12161885,\n",
       "        0.13875365, -0.10543536,  0.1133725 , -0.04878392,  0.02331437,\n",
       "       -0.1019199 ,  0.27709708,  0.06472345,  0.01585715,  0.12199115,\n",
       "       -0.04790941,  0.11972708,  0.02711636, -0.0875293 ,  0.09650326,\n",
       "        0.19493997, -0.02745498,  0.00250377,  0.07074796,  0.11411554,\n",
       "        0.19009888, -0.07684618,  0.08687522,  0.01784826, -0.11686379,\n",
       "        0.13255355, -0.06983697, -0.07092857, -0.06289294, -0.03779208,\n",
       "       -0.00807454, -0.08978826,  0.10044585,  0.05361647, -0.07717983,\n",
       "       -0.07854116, -0.03607492,  0.08362368,  0.12428655,  0.09205086,\n",
       "       -0.06187516,  0.23629829, -0.04901069,  0.05036921,  0.1876305 ,\n",
       "        0.1477668 , -0.099998  , -0.16505939,  0.03440215, -0.02177471,\n",
       "        0.14223373, -0.05831927,  0.09625965,  0.06793021,  0.09265986,\n",
       "       -0.00259128, -0.01015103,  0.09163   , -0.06636903, -0.1122276 ,\n",
       "       -0.00874658,  0.0084533 ,  0.05468522,  0.11282286,  0.21089439,\n",
       "       -0.04754286, -0.14960536,  0.1299063 ,  0.25629777,  0.06042645,\n",
       "       -0.04991091,  0.31058282, -0.10603262,  0.03222882,  0.11525383,\n",
       "        0.11214577,  0.1430212 , -0.11533346, -0.06045258,  0.10679992,\n",
       "        0.29308617, -0.21296319, -0.11155503, -0.09902865,  0.09256038,\n",
       "       -0.05532592, -0.2484073 , -0.07749059, -0.04624774,  0.09025349,\n",
       "       -0.0107998 , -0.0994845 ,  0.03770782, -0.095424  ,  0.15444277,\n",
       "        0.17897786, -0.07392191,  0.23015314, -0.12985477, -0.18336004,\n",
       "       -0.11278943, -0.07762662,  0.04168941,  0.24057631,  0.04324254,\n",
       "        0.24385788,  0.02901646, -0.01480209,  0.23947832,  0.09877372,\n",
       "       -0.07287943,  0.0299808 , -0.00321367, -0.09811126,  0.12788171,\n",
       "       -0.12348733, -0.11208726,  0.06959263, -0.08463363,  0.04852872,\n",
       "        0.09566014, -0.24370775, -0.08395067, -0.06975017, -0.20984131,\n",
       "        0.10656552, -0.15482204,  0.03055314,  0.07711248,  0.22494818,\n",
       "       -0.03620499,  0.02109094, -0.04506844,  0.09299686,  0.03315258,\n",
       "       -0.03903901, -0.11495807,  0.30616981, -0.15104091, -0.05468432,\n",
       "       -0.07708869,  0.01963159,  0.12526207,  0.47837621, -0.09724386,\n",
       "        0.08781943, -0.0777515 ,  0.28546038, -0.27956307, -0.0890204 ,\n",
       "        0.09127615, -0.18049273, -0.12777737, -0.05164996, -0.02692593,\n",
       "        0.00370617, -0.1412314 , -0.16756913, -0.14260875,  0.0883661 ,\n",
       "        0.31519216, -0.12521002,  0.13288458, -0.25221744,  0.21247528,\n",
       "       -0.00604237, -0.1073035 , -0.13426255,  0.03112797, -0.14077806,\n",
       "        0.03619255, -0.03758753,  0.13467592,  0.05120847, -0.04468783,\n",
       "       -0.01955738,  0.00368612, -0.12210057, -0.04360028,  0.24367468,\n",
       "       -0.1918464 , -0.02458055,  0.22725508, -0.01994203, -0.00201876], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[u'實惠']\n",
    "#做單詞查詢，可以看到這個詞與其他字詞的餘弦相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link:https://blog.liang2.tw/2015Talk-Chinese-Search/#tf-idf-in-action\n",
    "# Link:http://city.shaform.com/blog/2014/11/04/word2vec.html\n",
    "# Link:http://blog.csdn.net/heyongluoyao8/article/details/43488765\n",
    "# Link:http://ju.outofmemory.cn/entry/80023\n",
    "# Link:https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words\n",
    "# Link:https://read01.com/J8oGa.html\n",
    "# Link:https://ingramchen.io/blog/2014/06/elasticsearch.html\n",
    "# Link:https://radimrehurek.com/gensim/models/word2vec.html\n",
    "# Link:http://city.shaform.com/blog/2015/08/30/spark-for-word2vec.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
